
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "generated/autoexamples/GPU/example_learn_samples_multicoil.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_generated_autoexamples_GPU_example_learn_samples_multicoil.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_generated_autoexamples_GPU_example_learn_samples_multicoil.py:


=========================================
Learn Sampling pattern for multi-coil MRI
=========================================

A small pytorch example to showcase learning k-space sampling patterns.
This example showcases the auto-diff capabilities of the NUFFT operator
wrt to k-space trajectory in mri-nufft.

Briefly, in this example we try to learn the k-space samples :math:`\mathbf{K}` for the following cost function:

.. math::

    \mathbf{\hat{K}} =  arg \min_{\mathbf{K}} ||  \sum_{\ell=1}^LS_\ell^* \mathcal{F}_\mathbf{K}^* D_\mathbf{K} \mathcal{F}_\mathbf{K} x_\ell - \mathbf{x}_{sos} ||_2^2

where :math:`S_\ell` is the sensitivity map for the :math:`\ell`-th coil, :math:`\mathcal{F}_\mathbf{K}` is the forward NUFFT operator and :math:`D_\mathbf{K}` is the density compensators for trajectory :math:`\mathbf{K}`,  :math:`\mathbf{x}_\ell` is the image for the :math:`\ell`-th coil, and :math:`\mathbf{x}_{sos} = \sqrt{\sum_{\ell=1}^L x_\ell^2}` is the sum-of-squares image as target image to be reconstructed.

In this example, the forward NUFFT operator :math:`\mathcal{F}_\mathbf{K}` is implemented with `model.operator` while the SENSE operator ``model.sense_op`` models the term :math:`\mathbf{A} = \sum_{\ell=1}^LS_\ell^* \mathcal{F}_\mathbf{K}^* D_\mathbf{K}`.
For our data, we use a 2D slice of a 3D MRI image from the BrainWeb dataset, and the sensitivity maps are simulated using the `birdcage_maps` function from `sigpy.mri`.

.. note::
    To showcase the features of ``mri-nufft``, we use ``
    "cufinufft"`` backend for ``model.operator`` without density compensation and ``"gpunufft"`` backend for ``model.sense_op`` with density compensation.

.. warning::
    This example only showcases the autodiff capabilities, the learned sampling pattern is not scanner compliant as the scanner gradients required to implement it violate the hardware constraints. In practice, a projection :math:`\Pi_\mathcal{Q}(\mathbf{K})` into the scanner constraints set :math:`\mathcal{Q}` is recommended (see [Proj]_). This is implemented in the proprietary SPARKLING package [Sparks]_. Users are encouraged to contact the authors if they want to use it.

.. GENERATED FROM PYTHON SOURCE LINES 30-34

.. colab-link::
   :needs_gpu: 1

   !pip install mri-nufft[gpunufft] cufinufft sigpy scikit-image

.. GENERATED FROM PYTHON SOURCE LINES 36-38

Imports
-------

.. GENERATED FROM PYTHON SOURCE LINES 38-59

.. code-block:: Python

    import time
    import os
    import sys

    print(sys.path)
    print("Using backend:", os.environ.get("MRINUFFT_BACKEND"))
    import joblib
    import os

    import brainweb_dl as bwdl
    import matplotlib.pyplot as plt
    import numpy as np
    import torch
    from tqdm import tqdm
    from PIL import Image, ImageSequence

    from mrinufft import get_operator
    from mrinufft.extras import get_smaps
    from mrinufft.trajectories import initialize_2D_radial
    from sigpy.mri import birdcage_maps





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    ['/volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft', '/volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/mri-nufft/docs', '/volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/mri-nufft', '/volatile/github-ci-mind-inria/gpu_mind_runner/_work/_tool/Python/3.10.16/x64/lib/python310.zip', '/volatile/github-ci-mind-inria/gpu_mind_runner/_work/_tool/Python/3.10.16/x64/lib/python3.10', '/volatile/github-ci-mind-inria/gpu_mind_runner/_work/_tool/Python/3.10.16/x64/lib/python3.10/lib-dynload', '/volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages', '/volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/mri-nufft/examples/GPU']
    Using backend: cufinufft




.. GENERATED FROM PYTHON SOURCE LINES 60-65

Setup a simple class to learn trajectory
----------------------------------------
.. note::
    While we are only learning the NUFFT operator, we still need the gradient `wrt_data=True` to have all the gradients computed correctly.
    See [Projector]_ for more details.

.. GENERATED FROM PYTHON SOURCE LINES 65-124

.. code-block:: Python



    BACKEND = os.environ.get("MRINUFFT_BACKEND", "cufinufft")


    class Model(torch.nn.Module):
        def __init__(self, inital_trajectory, n_coils, img_size=(256, 256)):
            super(Model, self).__init__()
            self.trajectory = torch.nn.Parameter(
                data=torch.Tensor(inital_trajectory),
                requires_grad=True,
            )
            sample_points = inital_trajectory.reshape(-1, inital_trajectory.shape[-1])
            # A simple acquisition model simulated with a forward NUFFT operator. We dont need density compensation here.
            # The trajectory is scaled by 2*pi for cufinufft backend.
            self.operator = get_operator(BACKEND, wrt_data=True, wrt_traj=True)(
                sample_points * 2 * np.pi,
                shape=img_size,
                n_coils=n_coils,
                squeeze_dims=False,
            )
            # A simple density compensated adjoint SENSE operator with sensitivity maps `smaps`.
            self.sense_op = get_operator(BACKEND, wrt_data=True, wrt_traj=True)(
                sample_points,
                shape=img_size,
                density=True,
                n_coils=n_coils,
                smaps=np.ones(
                    (n_coils, *img_size), dtype=np.complex64
                ),  # Dummy smaps, this is updated in forward pass
                squeeze_dims=False,
            )
            self.img_size = img_size

        def forward(self, x):
            """Forward pass of the model."""
            # Update the trajectory in the NUFFT operator.
            # The trajectory is scaled by 2*pi for cufinufft backend.
            # Note that the re-computation of density compensation happens internally.
            self.operator.samples = self.trajectory.clone() * 2 * np.pi
            self.sense_op.samples = self.trajectory.clone()

            # Simulate the acquisition process
            kspace = self.operator.op(x)

            # Recompute the sensitivity maps for the updated trajectory.
            self.sense_op.smaps, _ = get_smaps("low_frequency")(
                self.trajectory.detach().numpy(),
                self.img_size,
                kspace.detach(),
                backend=BACKEND,
                density=self.sense_op.density,
                blurr_factor=20,
            )
            # Reconstruction using the sense operator
            adjoint = self.sense_op.adj_op(kspace).abs()
            return adjoint / torch.mean(adjoint)









.. GENERATED FROM PYTHON SOURCE LINES 125-127

Util function to plot the state of the model
--------------------------------------------

.. GENERATED FROM PYTHON SOURCE LINES 127-148

.. code-block:: Python

    def plot_state(axs, mri_2D, traj, recon, loss=None, save_name=None):
        axs = axs.flatten()
        axs[0].imshow(np.abs(mri_2D), cmap="gray")
        axs[0].axis("off")
        axs[0].set_title("MR Image")
        axs[1].scatter(*traj.T, s=1)
        axs[1].set_title("Trajectory")
        axs[2].imshow(np.abs(recon[0][0].detach().cpu().numpy()), cmap="gray")
        axs[2].axis("off")
        axs[2].set_title("Reconstruction")
        if loss is not None:
            axs[3].plot(loss)
            axs[3].set_title("Loss")
            axs[3].grid("on")
        if save_name is not None:
            plt.savefig(save_name, bbox_inches="tight")
            plt.close()
        else:
            plt.show()









.. GENERATED FROM PYTHON SOURCE LINES 149-151

Setup model and optimizer
-------------------------

.. GENERATED FROM PYTHON SOURCE LINES 151-163

.. code-block:: Python

    n_coils = 6
    init_traj = (
        initialize_2D_radial(32, 256).astype(np.float32).reshape(-1, 2).astype(np.float32)
    )
    model = Model(init_traj, n_coils=n_coils, img_size=(256, 256))
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    schedulder = torch.optim.lr_scheduler.LinearLR(
        optimizer,
        start_factor=1,
        end_factor=0.1,
        total_iters=100,
    )




.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages/mrinufft/_utils.py:94: UserWarning: Samples will be rescaled to [-pi, pi), assuming they were in [-0.5, 0.5)
      warnings.warn(
    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages/mrinufft/_utils.py:99: UserWarning: Samples will be rescaled to [-0.5, 0.5), assuming they were in [-pi, pi)
      warnings.warn(




.. GENERATED FROM PYTHON SOURCE LINES 164-166

Setup data
----------

.. GENERATED FROM PYTHON SOURCE LINES 166-175

.. code-block:: Python

    mri_2D = torch.from_numpy(np.flipud(bwdl.get_mri(4, "T1")[80, ...]).astype(np.float32))
    mri_2D = mri_2D / torch.mean(mri_2D)
    smaps_simulated = torch.from_numpy(birdcage_maps((n_coils, *mri_2D.shape)))
    mcmri_2D = mri_2D[None].to(torch.complex64) * smaps_simulated
    model.eval()
    recon = model(mcmri_2D)
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    plot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon)




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_001.png
   :alt: MR Image, Trajectory, Reconstruction
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages/mrinufft/_utils.py:94: UserWarning: Samples will be rescaled to [-pi, pi), assuming they were in [-0.5, 0.5)
      warnings.warn(
    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages/mrinufft/_utils.py:99: UserWarning: Samples will be rescaled to [-0.5, 0.5), assuming they were in [-pi, pi)
      warnings.warn(
    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages/mrinufft/_utils.py:94: UserWarning: Samples will be rescaled to [-pi, pi), assuming they were in [-0.5, 0.5)
      warnings.warn(
    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/mri-nufft/examples/GPU/example_learn_samples_multicoil.py:129: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)
      axs[0].imshow(np.abs(mri_2D), cmap="gray")




.. GENERATED FROM PYTHON SOURCE LINES 176-178

Start training loop
-------------------

.. GENERATED FROM PYTHON SOURCE LINES 178-226

.. code-block:: Python

    losses = []
    image_files = []
    model.train()

    with tqdm(range(100), unit="steps") as tqdms:
        for i in tqdms:
            out = model(mcmri_2D)
            loss = torch.nn.functional.mse_loss(out, mri_2D[None, None])
            numpy_loss = loss.detach().cpu().numpy()
            tqdms.set_postfix({"loss": numpy_loss})
            losses.append(numpy_loss)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            schedulder.step()
            with torch.no_grad():
                # Clamp the value of trajectory between [-0.5, 0.5]
                for param in model.parameters():
                    param.clamp_(-0.5, 0.5)
            # Generate images for gif
            hashed = joblib.hash((i, "learn_traj", time.time()))
            filename = "/tmp/" + f"{hashed}.png"
            plt.clf()
            fig, axs = plt.subplots(2, 2, figsize=(10, 10))
            plot_state(
                axs,
                mri_2D,
                model.trajectory.detach().cpu().numpy(),
                out,
                losses,
                save_name=filename,
            )
            image_files.append(filename)


    # Make a GIF of all images.
    imgs = [Image.open(img) for img in image_files]
    imgs[0].save(
        "mrinufft_learn_traj_mc.gif",
        save_all=True,
        append_images=imgs[1:],
        optimize=False,
        duration=2,
        loop=0,
    )

    # sphinx_gallery_thumbnail_path = 'generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif'




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_002.png
   :alt: example learn samples multicoil
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/100 [00:00<?, ?steps/s]/volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages/mrinufft/_utils.py:99: UserWarning: Samples will be rescaled to [-0.5, 0.5), assuming they were in [-pi, pi)
      warnings.warn(
      0%|          | 0/100 [00:00<?, ?steps/s, loss=0.52812076]/volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages/mrinufft/operators/autodiff.py:98: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /pytorch/aten/src/ATen/native/Copy.cpp:307.)
      grad_traj = torch.transpose(torch.sum(grad_traj, dim=1), 0, 1).to(
      1%|          | 1/100 [00:00<01:12,  1.37steps/s, loss=0.52812076]      1%|          | 1/100 [00:00<01:12,  1.37steps/s, loss=0.31584173]      2%|▏         | 2/100 [00:01<01:10,  1.39steps/s, loss=0.31584173]      2%|▏         | 2/100 [00:01<01:10,  1.39steps/s, loss=0.24707069]      3%|▎         | 3/100 [00:02<01:09,  1.39steps/s, loss=0.24707069]      3%|▎         | 3/100 [00:02<01:09,  1.39steps/s, loss=0.24464402]      4%|▍         | 4/100 [00:02<01:10,  1.37steps/s, loss=0.24464402]      4%|▍         | 4/100 [00:03<01:10,  1.37steps/s, loss=0.26410273]      5%|▌         | 5/100 [00:03<01:14,  1.28steps/s, loss=0.26410273]      5%|▌         | 5/100 [00:03<01:14,  1.28steps/s, loss=0.1963247]       6%|▌         | 6/100 [00:04<01:12,  1.29steps/s, loss=0.1963247]      6%|▌         | 6/100 [00:04<01:12,  1.29steps/s, loss=0.15397243]      7%|▋         | 7/100 [00:05<01:11,  1.30steps/s, loss=0.15397243]      7%|▋         | 7/100 [00:05<01:11,  1.30steps/s, loss=0.16401833]      8%|▊         | 8/100 [00:06<01:18,  1.17steps/s, loss=0.16401833]      8%|▊         | 8/100 [00:06<01:18,  1.17steps/s, loss=0.15395054]      9%|▉         | 9/100 [00:07<01:16,  1.19steps/s, loss=0.15395054]      9%|▉         | 9/100 [00:07<01:16,  1.19steps/s, loss=0.17036977]     10%|█         | 10/100 [00:07<01:13,  1.23steps/s, loss=0.17036977]     10%|█         | 10/100 [00:08<01:13,  1.23steps/s, loss=0.16881123]     11%|█         | 11/100 [00:08<01:10,  1.26steps/s, loss=0.16881123]     11%|█         | 11/100 [00:08<01:10,  1.26steps/s, loss=0.15189472]     12%|█▏        | 12/100 [00:09<01:09,  1.26steps/s, loss=0.15189472]     12%|█▏        | 12/100 [00:09<01:09,  1.26steps/s, loss=0.16083032]     13%|█▎        | 13/100 [00:10<01:08,  1.27steps/s, loss=0.16083032]     13%|█▎        | 13/100 [00:10<01:08,  1.27steps/s, loss=0.1697787]      14%|█▍        | 14/100 [00:11<01:09,  1.25steps/s, loss=0.1697787]     14%|█▍        | 14/100 [00:11<01:09,  1.25steps/s, loss=0.1640903]     15%|█▌        | 15/100 [00:11<01:07,  1.25steps/s, loss=0.1640903]     15%|█▌        | 15/100 [00:12<01:07,  1.25steps/s, loss=0.14949574]     16%|█▌        | 16/100 [00:12<01:06,  1.27steps/s, loss=0.14949574]     16%|█▌        | 16/100 [00:12<01:06,  1.27steps/s, loss=0.14262813]     17%|█▋        | 17/100 [00:13<01:12,  1.14steps/s, loss=0.14262813]     17%|█▋        | 17/100 [00:13<01:12,  1.14steps/s, loss=0.13967678]     18%|█▊        | 18/100 [00:14<01:09,  1.18steps/s, loss=0.13967678]     18%|█▊        | 18/100 [00:14<01:09,  1.18steps/s, loss=0.13232759]     19%|█▉        | 19/100 [00:15<01:10,  1.15steps/s, loss=0.13232759]     19%|█▉        | 19/100 [00:15<01:10,  1.15steps/s, loss=0.12565918]     20%|██        | 20/100 [00:16<01:06,  1.20steps/s, loss=0.12565918]     20%|██        | 20/100 [00:16<01:06,  1.20steps/s, loss=0.12429785]     21%|██        | 21/100 [00:16<01:04,  1.23steps/s, loss=0.12429785]     21%|██        | 21/100 [00:17<01:04,  1.23steps/s, loss=0.122750685]     22%|██▏       | 22/100 [00:17<01:02,  1.25steps/s, loss=0.122750685]     22%|██▏       | 22/100 [00:17<01:02,  1.25steps/s, loss=0.12104416]      23%|██▎       | 23/100 [00:18<01:00,  1.26steps/s, loss=0.12104416]     23%|██▎       | 23/100 [00:18<01:00,  1.26steps/s, loss=0.11668144]     24%|██▍       | 24/100 [00:19<00:58,  1.29steps/s, loss=0.11668144]     24%|██▍       | 24/100 [00:19<00:58,  1.29steps/s, loss=0.11459418]     25%|██▌       | 25/100 [00:19<00:57,  1.30steps/s, loss=0.11459418]     25%|██▌       | 25/100 [00:20<00:57,  1.30steps/s, loss=0.1139054]      26%|██▌       | 26/100 [00:20<01:02,  1.18steps/s, loss=0.1139054]     26%|██▌       | 26/100 [00:21<01:02,  1.18steps/s, loss=0.110338904]     27%|██▋       | 27/100 [00:21<01:00,  1.21steps/s, loss=0.110338904]     27%|██▋       | 27/100 [00:21<01:00,  1.21steps/s, loss=0.10748167]      28%|██▊       | 28/100 [00:22<00:57,  1.26steps/s, loss=0.10748167]     28%|██▊       | 28/100 [00:22<00:57,  1.26steps/s, loss=0.10630634]     29%|██▉       | 29/100 [00:23<00:55,  1.28steps/s, loss=0.10630634]     29%|██▉       | 29/100 [00:23<00:55,  1.28steps/s, loss=0.10974491]     30%|███       | 30/100 [00:23<00:53,  1.30steps/s, loss=0.10974491]     30%|███       | 30/100 [00:24<00:53,  1.30steps/s, loss=0.11348617]     31%|███       | 31/100 [00:24<00:53,  1.30steps/s, loss=0.11348617]     31%|███       | 31/100 [00:24<00:53,  1.30steps/s, loss=0.11255805]     32%|███▏      | 32/100 [00:25<00:51,  1.31steps/s, loss=0.11255805]     32%|███▏      | 32/100 [00:25<00:51,  1.31steps/s, loss=0.10704605]     33%|███▎      | 33/100 [00:26<00:50,  1.32steps/s, loss=0.10704605]     33%|███▎      | 33/100 [00:26<00:50,  1.32steps/s, loss=0.101287454]     34%|███▍      | 34/100 [00:26<00:49,  1.32steps/s, loss=0.101287454]     34%|███▍      | 34/100 [00:27<00:49,  1.32steps/s, loss=0.09889321]      35%|███▌      | 35/100 [00:27<00:53,  1.21steps/s, loss=0.09889321]     35%|███▌      | 35/100 [00:28<00:53,  1.21steps/s, loss=0.09799588]     36%|███▌      | 36/100 [00:28<00:52,  1.23steps/s, loss=0.09799588]     36%|███▌      | 36/100 [00:28<00:52,  1.23steps/s, loss=0.09710219]     37%|███▋      | 37/100 [00:29<00:50,  1.26steps/s, loss=0.09710219]     37%|███▋      | 37/100 [00:29<00:50,  1.26steps/s, loss=0.09561971]     38%|███▊      | 38/100 [00:30<00:49,  1.25steps/s, loss=0.09561971]     38%|███▊      | 38/100 [00:30<00:49,  1.25steps/s, loss=0.093033746]     39%|███▉      | 39/100 [00:31<00:47,  1.29steps/s, loss=0.093033746]     39%|███▉      | 39/100 [00:31<00:47,  1.29steps/s, loss=0.09122008]      40%|████      | 40/100 [00:31<00:45,  1.31steps/s, loss=0.09122008]     40%|████      | 40/100 [00:31<00:45,  1.31steps/s, loss=0.09165923]     41%|████      | 41/100 [00:32<00:44,  1.32steps/s, loss=0.09165923]     41%|████      | 41/100 [00:32<00:44,  1.32steps/s, loss=0.09162952]     42%|████▏     | 42/100 [00:33<00:43,  1.33steps/s, loss=0.09162952]     42%|████▏     | 42/100 [00:33<00:43,  1.33steps/s, loss=0.09142776]     43%|████▎     | 43/100 [00:34<00:43,  1.32steps/s, loss=0.09142776]     43%|████▎     | 43/100 [00:34<00:43,  1.32steps/s, loss=0.09265852]     44%|████▍     | 44/100 [00:34<00:42,  1.32steps/s, loss=0.09265852]     44%|████▍     | 44/100 [00:34<00:42,  1.32steps/s, loss=0.093469866]     45%|████▌     | 45/100 [00:35<00:45,  1.21steps/s, loss=0.093469866]     45%|████▌     | 45/100 [00:35<00:45,  1.21steps/s, loss=0.09233388]      46%|████▌     | 46/100 [00:36<00:43,  1.24steps/s, loss=0.09233388]     46%|████▌     | 46/100 [00:36<00:43,  1.24steps/s, loss=0.09149455]     47%|████▋     | 47/100 [00:37<00:41,  1.27steps/s, loss=0.09149455]     47%|████▋     | 47/100 [00:37<00:41,  1.27steps/s, loss=0.093376]       48%|████▊     | 48/100 [00:38<00:40,  1.29steps/s, loss=0.093376]     48%|████▊     | 48/100 [00:38<00:40,  1.29steps/s, loss=0.0953729]     49%|████▉     | 49/100 [00:38<00:39,  1.28steps/s, loss=0.0953729]     49%|████▉     | 49/100 [00:38<00:39,  1.28steps/s, loss=0.094671994]     50%|█████     | 50/100 [00:39<00:38,  1.29steps/s, loss=0.094671994]     50%|█████     | 50/100 [00:39<00:38,  1.29steps/s, loss=0.090240136]     51%|█████     | 51/100 [00:40<00:37,  1.30steps/s, loss=0.090240136]     51%|█████     | 51/100 [00:40<00:37,  1.30steps/s, loss=0.09041297]      52%|█████▏    | 52/100 [00:41<00:37,  1.29steps/s, loss=0.09041297]     52%|█████▏    | 52/100 [00:41<00:37,  1.29steps/s, loss=0.09328838]     53%|█████▎    | 53/100 [00:41<00:36,  1.29steps/s, loss=0.09328838]     53%|█████▎    | 53/100 [00:42<00:36,  1.29steps/s, loss=0.09110165]     54%|█████▍    | 54/100 [00:42<00:35,  1.29steps/s, loss=0.09110165]     54%|█████▍    | 54/100 [00:42<00:35,  1.29steps/s, loss=0.08741824]     55%|█████▌    | 55/100 [00:43<00:39,  1.15steps/s, loss=0.08741824]     55%|█████▌    | 55/100 [00:43<00:39,  1.15steps/s, loss=0.08636105]     56%|█████▌    | 56/100 [00:44<00:36,  1.20steps/s, loss=0.08636105]     56%|█████▌    | 56/100 [00:44<00:36,  1.20steps/s, loss=0.08586333]     57%|█████▋    | 57/100 [00:45<00:34,  1.23steps/s, loss=0.08586333]     57%|█████▋    | 57/100 [00:45<00:34,  1.23steps/s, loss=0.08374846]     58%|█████▊    | 58/100 [00:46<00:33,  1.25steps/s, loss=0.08374846]     58%|█████▊    | 58/100 [00:46<00:33,  1.25steps/s, loss=0.08259422]     59%|█████▉    | 59/100 [00:46<00:32,  1.26steps/s, loss=0.08259422]     59%|█████▉    | 59/100 [00:46<00:32,  1.26steps/s, loss=0.08289114]     60%|██████    | 60/100 [00:47<00:31,  1.28steps/s, loss=0.08289114]     60%|██████    | 60/100 [00:47<00:31,  1.28steps/s, loss=0.0829225]      61%|██████    | 61/100 [00:48<00:30,  1.27steps/s, loss=0.0829225]     61%|██████    | 61/100 [00:48<00:30,  1.27steps/s, loss=0.08173855]     62%|██████▏   | 62/100 [00:49<00:29,  1.28steps/s, loss=0.08173855]     62%|██████▏   | 62/100 [00:49<00:29,  1.28steps/s, loss=0.0805434]      63%|██████▎   | 63/100 [00:49<00:28,  1.28steps/s, loss=0.0805434]     63%|██████▎   | 63/100 [00:50<00:28,  1.28steps/s, loss=0.079894766]     64%|██████▍   | 64/100 [00:50<00:28,  1.27steps/s, loss=0.079894766]     64%|██████▍   | 64/100 [00:50<00:28,  1.27steps/s, loss=0.07917805]      65%|██████▌   | 65/100 [00:51<00:29,  1.18steps/s, loss=0.07917805]     65%|██████▌   | 65/100 [00:51<00:29,  1.18steps/s, loss=0.07874158]     66%|██████▌   | 66/100 [00:52<00:27,  1.23steps/s, loss=0.07874158]     66%|██████▌   | 66/100 [00:52<00:27,  1.23steps/s, loss=0.07888587]     67%|██████▋   | 67/100 [00:53<00:26,  1.25steps/s, loss=0.07888587]     67%|██████▋   | 67/100 [00:53<00:26,  1.25steps/s, loss=0.07863541]     68%|██████▊   | 68/100 [00:53<00:25,  1.26steps/s, loss=0.07863541]     68%|██████▊   | 68/100 [00:54<00:25,  1.26steps/s, loss=0.077393174]     69%|██████▉   | 69/100 [00:54<00:24,  1.28steps/s, loss=0.077393174]     69%|██████▉   | 69/100 [00:54<00:24,  1.28steps/s, loss=0.07585502]      70%|███████   | 70/100 [00:55<00:23,  1.26steps/s, loss=0.07585502]     70%|███████   | 70/100 [00:55<00:23,  1.26steps/s, loss=0.074854106]     71%|███████   | 71/100 [00:56<00:23,  1.25steps/s, loss=0.074854106]     71%|███████   | 71/100 [00:56<00:23,  1.25steps/s, loss=0.07413638]      72%|███████▏  | 72/100 [00:57<00:22,  1.26steps/s, loss=0.07413638]     72%|███████▏  | 72/100 [00:57<00:22,  1.26steps/s, loss=0.07309757]     73%|███████▎  | 73/100 [00:57<00:21,  1.27steps/s, loss=0.07309757]     73%|███████▎  | 73/100 [00:58<00:21,  1.27steps/s, loss=0.07194196]     74%|███████▍  | 74/100 [00:58<00:22,  1.17steps/s, loss=0.07194196]     74%|███████▍  | 74/100 [00:59<00:22,  1.17steps/s, loss=0.07124798]     75%|███████▌  | 75/100 [00:59<00:20,  1.23steps/s, loss=0.07124798]     75%|███████▌  | 75/100 [00:59<00:20,  1.23steps/s, loss=0.07102366]     76%|███████▌  | 76/100 [01:00<00:18,  1.28steps/s, loss=0.07102366]     76%|███████▌  | 76/100 [01:00<00:18,  1.28steps/s, loss=0.07094701]     77%|███████▋  | 77/100 [01:01<00:17,  1.31steps/s, loss=0.07094701]     77%|███████▋  | 77/100 [01:01<00:17,  1.31steps/s, loss=0.0707346]      78%|███████▊  | 78/100 [01:01<00:16,  1.32steps/s, loss=0.0707346]     78%|███████▊  | 78/100 [01:02<00:16,  1.32steps/s, loss=0.07037884]     79%|███████▉  | 79/100 [01:02<00:15,  1.34steps/s, loss=0.07037884]     79%|███████▉  | 79/100 [01:02<00:15,  1.34steps/s, loss=0.06997875]     80%|████████  | 80/100 [01:03<00:14,  1.35steps/s, loss=0.06997875]     80%|████████  | 80/100 [01:03<00:14,  1.35steps/s, loss=0.06957336]     81%|████████  | 81/100 [01:03<00:13,  1.36steps/s, loss=0.06957336]     81%|████████  | 81/100 [01:04<00:13,  1.36steps/s, loss=0.069181025]     82%|████████▏ | 82/100 [01:04<00:13,  1.37steps/s, loss=0.069181025]     82%|████████▏ | 82/100 [01:04<00:13,  1.37steps/s, loss=0.06884338]      83%|████████▎ | 83/100 [01:05<00:13,  1.26steps/s, loss=0.06884338]     83%|████████▎ | 83/100 [01:05<00:13,  1.26steps/s, loss=0.068569556]     84%|████████▍ | 84/100 [01:06<00:12,  1.29steps/s, loss=0.068569556]     84%|████████▍ | 84/100 [01:06<00:12,  1.29steps/s, loss=0.068331]        85%|████████▌ | 85/100 [01:07<00:11,  1.31steps/s, loss=0.068331]     85%|████████▌ | 85/100 [01:07<00:11,  1.31steps/s, loss=0.06806123]     86%|████████▌ | 86/100 [01:07<00:10,  1.31steps/s, loss=0.06806123]     86%|████████▌ | 86/100 [01:08<00:10,  1.31steps/s, loss=0.067699]       87%|████████▋ | 87/100 [01:08<00:09,  1.31steps/s, loss=0.067699]     87%|████████▋ | 87/100 [01:08<00:09,  1.31steps/s, loss=0.067284785]     88%|████████▊ | 88/100 [01:09<00:09,  1.32steps/s, loss=0.067284785]     88%|████████▊ | 88/100 [01:09<00:09,  1.32steps/s, loss=0.06685479]      89%|████████▉ | 89/100 [01:10<00:08,  1.32steps/s, loss=0.06685479]     89%|████████▉ | 89/100 [01:10<00:08,  1.32steps/s, loss=0.066396296]     90%|█████████ | 90/100 [01:10<00:07,  1.33steps/s, loss=0.066396296]     90%|█████████ | 90/100 [01:11<00:07,  1.33steps/s, loss=0.06591979]      91%|█████████ | 91/100 [01:11<00:06,  1.35steps/s, loss=0.06591979]     91%|█████████ | 91/100 [01:11<00:06,  1.35steps/s, loss=0.06545127]     92%|█████████▏| 92/100 [01:12<00:05,  1.34steps/s, loss=0.06545127]     92%|█████████▏| 92/100 [01:12<00:05,  1.34steps/s, loss=0.06501619]     93%|█████████▎| 93/100 [01:13<00:05,  1.19steps/s, loss=0.06501619]     93%|█████████▎| 93/100 [01:13<00:05,  1.19steps/s, loss=0.06462623]     94%|█████████▍| 94/100 [01:14<00:04,  1.24steps/s, loss=0.06462623]     94%|█████████▍| 94/100 [01:14<00:04,  1.24steps/s, loss=0.06427458]     95%|█████████▌| 95/100 [01:14<00:03,  1.28steps/s, loss=0.06427458]     95%|█████████▌| 95/100 [01:15<00:03,  1.28steps/s, loss=0.06395267]     96%|█████████▌| 96/100 [01:15<00:03,  1.31steps/s, loss=0.06395267]     96%|█████████▌| 96/100 [01:15<00:03,  1.31steps/s, loss=0.06365092]     97%|█████████▋| 97/100 [01:16<00:02,  1.32steps/s, loss=0.06365092]     97%|█████████▋| 97/100 [01:16<00:02,  1.32steps/s, loss=0.06336142]     98%|█████████▊| 98/100 [01:17<00:01,  1.33steps/s, loss=0.06336142]     98%|█████████▊| 98/100 [01:17<00:01,  1.33steps/s, loss=0.063084364]     99%|█████████▉| 99/100 [01:17<00:00,  1.33steps/s, loss=0.063084364]     99%|█████████▉| 99/100 [01:18<00:00,  1.33steps/s, loss=0.06282349]     100%|██████████| 100/100 [01:18<00:00,  1.32steps/s, loss=0.06282349]    100%|██████████| 100/100 [01:18<00:00,  1.27steps/s, loss=0.06282349]




.. GENERATED FROM PYTHON SOURCE LINES 255-259

.. image-sg:: /generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif
   :alt: example learn_samples
   :srcset: /generated/autoexamples/GPU/images/mrinufft_learn_traj_mc.gif
   :class: sphx-glr-single-img

.. GENERATED FROM PYTHON SOURCE LINES 261-263

Trained trajectory
------------------

.. GENERATED FROM PYTHON SOURCE LINES 263-270

.. code-block:: Python

    model.eval()
    recon = model(mcmri_2D)
    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
    plot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon, losses)
    plt.show()





.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_003.png
   :alt: MR Image, Trajectory, Reconstruction, Loss
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_learn_samples_multicoil_003.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 271-286

References
==========

.. [Proj] N. Chauffert, P. Weiss, J. Kahn and P. Ciuciu, "A Projection Algorithm for
          Gradient Waveforms Design in Magnetic Resonance Imaging," in
          IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2026-2039, Sept. 2016,
          doi: 10.1109/TMI.2016.2544251.
.. [Sparks] G. R. Chaithya, P. Weiss, G. Daval-Frérot, A. Massire, A. Vignaud and P. Ciuciu,
          "Optimizing Full 3D SPARKLING Trajectories for High-Resolution Magnetic
          Resonance Imaging," in IEEE Transactions on Medical Imaging, vol. 41, no. 8,
          pp. 2105-2117, Aug. 2022, doi: 10.1109/TMI.2022.3157269.
.. [Projector] Chaithya GR, and Philippe Ciuciu. 2023. "Jointly Learning Non-Cartesian
          k-Space Trajectories and Reconstruction Networks for 2D and 3D MR Imaging
          through Projection" Bioengineering 10, no. 2: 158.
          https://doi.org/10.3390/bioengineering10020158


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 28.250 seconds)


.. _sphx_glr_download_generated_autoexamples_GPU_example_learn_samples_multicoil.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mind-inria/mri-nufft/gh-pages?urlpath=lab/tree/examples/generated/autoexamples/GPU/example_learn_samples_multicoil.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_learn_samples_multicoil.ipynb <example_learn_samples_multicoil.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_learn_samples_multicoil.py <example_learn_samples_multicoil.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: example_learn_samples_multicoil.zip <example_learn_samples_multicoil.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
