
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "generated/autoexamples/GPU/example_fastMRI_UNet.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_generated_autoexamples_GPU_example_fastMRI_UNet.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_generated_autoexamples_GPU_example_fastMRI_UNet.py:


==================
Simple UNet model.
==================

This model is a simplified version of the U-Net architecture,
which is widely used for image segmentation tasks.
This is implemented in the proprietary FASTMRI package [fastmri]_.

The U-Net model consists of an encoder (downsampling path) and
a decoder (upsampling path) with skip connections between corresponding
layers in the encoder and decoder.
These skip connections help in retaining spatial information
that is lost during the downsampling process.

The primary purpose of this model is to perform image reconstruction tasks,
specifically for MRI images.
It takes an input MRI image and reconstructs it to improve the image quality
or to recover missing parts of the image.

This implementation of the UNet model was pulled from the FastMRI Facebook
repository, which is a collaborative research project aimed at advancing
the field of medical imaging using machine learning techniques.

.. math::

    \mathbf{\hat{x}} = \mathrm{arg} \min_{\mathbf{x}} || \mathcal{U}_\mathbf{\theta}(\mathbf{y}) - \mathbf{x} ||_2^2

where :math:`\mathbf{\hat{x}}` is the reconstructed MRI image, :math:`\mathbf{x}` is the ground truth image,
:math:`\mathbf{y}` is the input MRI image (e.g., k-space data), and :math:`\mathcal{U}_\mathbf{\theta}` is the U-Net model parameterized by :math:`\theta`.

.. warning::
    We train on a single image here. In practice, this should be done on a database like fastMRI [fastmri]_.

.. GENERATED FROM PYTHON SOURCE LINES 37-41

.. colab-link::
   :needs_gpu: 1

   !pip install mri-nufft[gpunufft] scikit-image fastmri

.. GENERATED FROM PYTHON SOURCE LINES 43-44

Imports

.. GENERATED FROM PYTHON SOURCE LINES 44-61

.. code-block:: Python

    import os
    from pathlib import Path
    import shutil
    import brainweb_dl as bwdl
    import matplotlib.pyplot as plt
    import numpy as np
    import torch
    from tqdm import tqdm
    import time
    import joblib
    from PIL import Image
    import tempfile as tmp

    from fastmri.models import Unet
    from mrinufft import get_operator
    from mrinufft.trajectories import initialize_2D_cones








.. GENERATED FROM PYTHON SOURCE LINES 62-63

Setup a simple class for the U-Net model

.. GENERATED FROM PYTHON SOURCE LINES 63-87

.. code-block:: Python

    BACKEND = os.environ.get("MRINUFFT_BACKEND", "cufinufft")


    class Model(torch.nn.Module):
        """Model for MRI reconstruction using a U-Net."""

        def __init__(self, initial_trajectory):
            super().__init__()
            self.operator = get_operator(BACKEND, wrt_data=True)(
                initial_trajectory,
                shape=(256, 256),
                density=True,
                squeeze_dims=False,
            )
            self.unet = Unet(in_chans=1, out_chans=1, chans=32, num_pool_layers=4)

        def forward(self, kspace):
            """Forward pass of the model."""
            image = self.operator.adj_op(kspace)
            recon = self.unet(image.float()).abs()
            recon /= torch.mean(recon)
            return recon









.. GENERATED FROM PYTHON SOURCE LINES 88-89

Utility function to plot the state of the model

.. GENERATED FROM PYTHON SOURCE LINES 89-124

.. code-block:: Python

    def plot_state(axs, mri_2D, traj, recon, loss=None, save_name=None):
        """Image plotting function.

        Plot the original MRI image, the trajectory, the reconstructed image,
        and the loss curve (if provided). Saves the plot if a filename is provided.

        Parameters
        ----------
        axs (numpy array): Array of matplotlib axes to plot on.
        mri_2D (torch.Tensor): Original MRI image.
        traj : Trajectory.
        recon (torch.Tensor): Reconstructed image after training.
        loss (list, optional): List of loss values to plot. Defaults to None.
        save_name (str, optional): Filename to save the plot. Defaults to None.
        """
        axs = axs.flatten()
        axs[0].imshow(np.abs(mri_2D[0]), cmap="gray")
        axs[0].axis("off")
        axs[0].set_title("MR Image")
        axs[1].scatter(*traj.T, s=0.5)
        axs[1].set_title("Trajectory")
        axs[2].imshow(np.abs(recon[0][0].detach().cpu().numpy()), cmap="gray")
        axs[2].axis("off")
        axs[2].set_title("Reconstruction")
        if loss is not None:
            axs[3].plot(loss)
            axs[3].grid("on")
            axs[3].set_title("Loss")
        if save_name is not None:
            plt.savefig(save_name, bbox_inches="tight")
            plt.close()
        else:
            plt.show()









.. GENERATED FROM PYTHON SOURCE LINES 125-126

Setup Inputs (models, trajectory and image)

.. GENERATED FROM PYTHON SOURCE LINES 126-130

.. code-block:: Python

    init_traj = initialize_2D_cones(32, 256).reshape(-1, 2).astype(np.float32)
    model = Model(init_traj)
    model.eval()





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages/mrinufft/_utils.py:94: UserWarning: Samples will be rescaled to [-pi, pi), assuming they were in [-0.5, 0.5)
      warnings.warn(
    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/venv/lib/python3.10/site-packages/mrinufft/_utils.py:99: UserWarning: Samples will be rescaled to [-0.5, 0.5), assuming they were in [-pi, pi)
      warnings.warn(

    Model(
      (operator): MRINufftAutoGrad()
      (unet): Unet(
        (down_sample_layers): ModuleList(
          (0): ConvBlock(
            (layers): Sequential(
              (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
              (3): Dropout2d(p=0.0, inplace=False)
              (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (5): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (6): LeakyReLU(negative_slope=0.2, inplace=True)
              (7): Dropout2d(p=0.0, inplace=False)
            )
          )
          (1): ConvBlock(
            (layers): Sequential(
              (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
              (3): Dropout2d(p=0.0, inplace=False)
              (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (6): LeakyReLU(negative_slope=0.2, inplace=True)
              (7): Dropout2d(p=0.0, inplace=False)
            )
          )
          (2): ConvBlock(
            (layers): Sequential(
              (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
              (3): Dropout2d(p=0.0, inplace=False)
              (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (6): LeakyReLU(negative_slope=0.2, inplace=True)
              (7): Dropout2d(p=0.0, inplace=False)
            )
          )
          (3): ConvBlock(
            (layers): Sequential(
              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
              (3): Dropout2d(p=0.0, inplace=False)
              (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (5): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (6): LeakyReLU(negative_slope=0.2, inplace=True)
              (7): Dropout2d(p=0.0, inplace=False)
            )
          )
        )
        (conv): ConvBlock(
          (layers): Sequential(
            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): LeakyReLU(negative_slope=0.2, inplace=True)
            (3): Dropout2d(p=0.0, inplace=False)
            (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (5): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (6): LeakyReLU(negative_slope=0.2, inplace=True)
            (7): Dropout2d(p=0.0, inplace=False)
          )
        )
        (up_conv): ModuleList(
          (0): ConvBlock(
            (layers): Sequential(
              (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
              (3): Dropout2d(p=0.0, inplace=False)
              (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (5): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (6): LeakyReLU(negative_slope=0.2, inplace=True)
              (7): Dropout2d(p=0.0, inplace=False)
            )
          )
          (1): ConvBlock(
            (layers): Sequential(
              (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
              (3): Dropout2d(p=0.0, inplace=False)
              (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (6): LeakyReLU(negative_slope=0.2, inplace=True)
              (7): Dropout2d(p=0.0, inplace=False)
            )
          )
          (2): ConvBlock(
            (layers): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
              (3): Dropout2d(p=0.0, inplace=False)
              (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (6): LeakyReLU(negative_slope=0.2, inplace=True)
              (7): Dropout2d(p=0.0, inplace=False)
            )
          )
          (3): Sequential(
            (0): ConvBlock(
              (layers): Sequential(
                (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (2): LeakyReLU(negative_slope=0.2, inplace=True)
                (3): Dropout2d(p=0.0, inplace=False)
                (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (5): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
                (6): LeakyReLU(negative_slope=0.2, inplace=True)
                (7): Dropout2d(p=0.0, inplace=False)
              )
            )
            (1): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
          )
        )
        (up_transpose_conv): ModuleList(
          (0): TransposeConvBlock(
            (layers): Sequential(
              (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2), bias=False)
              (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
            )
          )
          (1): TransposeConvBlock(
            (layers): Sequential(
              (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)
              (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
            )
          )
          (2): TransposeConvBlock(
            (layers): Sequential(
              (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)
              (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
            )
          )
          (3): TransposeConvBlock(
            (layers): Sequential(
              (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)
              (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
              (2): LeakyReLU(negative_slope=0.2, inplace=True)
            )
          )
        )
      )
    )



.. GENERATED FROM PYTHON SOURCE LINES 131-132

Get the image on which we will train our U-Net Model

.. GENERATED FROM PYTHON SOURCE LINES 132-145

.. code-block:: Python

    mri_2D = torch.Tensor(np.flipud(bwdl.get_mri(4, "T1")[80, ...]).astype(np.complex64))[
        None
    ]
    mri_2D = mri_2D / torch.mean(mri_2D)
    kspace_mri_2D = model.operator.op(mri_2D)

    # Before training, here is the simple reconstruction we have using a
    # density compensated adjoint.
    dc_adjoint = model.operator.adj_op(kspace_mri_2D)
    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    plot_state(axs, mri_2D, init_traj, dc_adjoint)





.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_fastMRI_UNet_001.png
   :alt: MR Image, Trajectory, Reconstruction
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_fastMRI_UNet_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/mri-nufft/examples/GPU/example_fastMRI_UNet.py:132: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /pytorch/aten/src/ATen/native/Copy.cpp:307.)
      mri_2D = torch.Tensor(np.flipud(bwdl.get_mri(4, "T1")[80, ...]).astype(np.complex64))[
    /volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/mri-nufft/examples/GPU/example_fastMRI_UNet.py:105: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)
      axs[0].imshow(np.abs(mri_2D[0]), cmap="gray")




.. GENERATED FROM PYTHON SOURCE LINES 146-147

Start training loop

.. GENERATED FROM PYTHON SOURCE LINES 147-193

.. code-block:: Python

    num_epochs = 100
    optimizer = torch.optim.RAdam(model.parameters(), lr=1e-3)
    losses = []  # Store the loss values and create an animation
    image_files = []  # Store the images to create a gif
    model.train()

    with tqdm(range(num_epochs), unit="steps") as tqdms:
        for i in tqdms:
            out = model(kspace_mri_2D)  # Forward pass

            loss = torch.nn.functional.l1_loss(out, mri_2D[None])  # Compute loss
            tqdms.set_postfix({"loss": loss.item()})  # Update progress bar
            losses.append(loss.item())  # Store loss value

            optimizer.zero_grad()  # Zero gradients
            loss.backward()  # Backward pass
            optimizer.step()  # Update weights

            # Generate images for gif
            hashed = joblib.hash((i, "learn_traj", time.time()))
            filename = f"{tmp.NamedTemporaryFile().name}.png"
            fig, axs = plt.subplots(2, 2, figsize=(10, 10))
            plot_state(
                axs,
                mri_2D,
                init_traj,
                out,
                losses,
                save_name=filename,
            )
            image_files.append(filename)


    # Make a GIF of all images.
    imgs = [Image.open(img) for img in image_files]
    imgs[0].save(
        "mrinufft_learn_unet.gif",
        save_all=True,
        append_images=imgs[1:],
        optimize=False,
        duration=2,
        loop=0,
    )

    # sphinx_gallery_thumbnail_path = 'generated/autoexamples/GPU/images/mrinufft_learn_unet.gif'





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|          | 0/100 [00:00<?, ?steps/s]      0%|          | 0/100 [00:00<?, ?steps/s, loss=1.18]/volatile/github-ci-mind-inria/gpu_mind_runner/_work/mri-nufft/mri-nufft/examples/GPU/example_fastMRI_UNet.py:105: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)
      axs[0].imshow(np.abs(mri_2D[0]), cmap="gray")
      1%|          | 1/100 [00:00<01:29,  1.10steps/s, loss=1.18]      1%|          | 1/100 [00:01<01:29,  1.10steps/s, loss=1.11]      2%|▏         | 2/100 [00:01<01:26,  1.13steps/s, loss=1.11]      2%|▏         | 2/100 [00:01<01:26,  1.13steps/s, loss=1.04]      3%|▎         | 3/100 [00:02<01:24,  1.14steps/s, loss=1.04]      3%|▎         | 3/100 [00:02<01:24,  1.14steps/s, loss=0.958]      4%|▍         | 4/100 [00:03<01:23,  1.15steps/s, loss=0.958]      4%|▍         | 4/100 [00:03<01:23,  1.15steps/s, loss=0.878]      5%|▌         | 5/100 [00:04<01:21,  1.16steps/s, loss=0.878]      5%|▌         | 5/100 [00:04<01:21,  1.16steps/s, loss=0.803]      6%|▌         | 6/100 [00:05<01:28,  1.06steps/s, loss=0.803]      6%|▌         | 6/100 [00:05<01:28,  1.06steps/s, loss=0.74]       7%|▋         | 7/100 [00:06<01:24,  1.09steps/s, loss=0.74]      7%|▋         | 7/100 [00:06<01:24,  1.09steps/s, loss=0.679]      8%|▊         | 8/100 [00:07<01:22,  1.12steps/s, loss=0.679]      8%|▊         | 8/100 [00:07<01:22,  1.12steps/s, loss=0.624]      9%|▉         | 9/100 [00:08<01:20,  1.13steps/s, loss=0.624]      9%|▉         | 9/100 [00:08<01:20,  1.13steps/s, loss=0.579]     10%|█         | 10/100 [00:08<01:18,  1.14steps/s, loss=0.579]     10%|█         | 10/100 [00:08<01:18,  1.14steps/s, loss=0.541]     11%|█         | 11/100 [00:09<01:17,  1.15steps/s, loss=0.541]     11%|█         | 11/100 [00:09<01:17,  1.15steps/s, loss=0.509]     12%|█▏        | 12/100 [00:10<01:16,  1.15steps/s, loss=0.509]     12%|█▏        | 12/100 [00:10<01:16,  1.15steps/s, loss=0.485]     13%|█▎        | 13/100 [00:11<01:16,  1.13steps/s, loss=0.485]     13%|█▎        | 13/100 [00:11<01:16,  1.13steps/s, loss=0.465]     14%|█▍        | 14/100 [00:12<01:16,  1.12steps/s, loss=0.465]     14%|█▍        | 14/100 [00:12<01:16,  1.12steps/s, loss=0.449]     15%|█▌        | 15/100 [00:13<01:15,  1.12steps/s, loss=0.449]     15%|█▌        | 15/100 [00:13<01:15,  1.12steps/s, loss=0.436]     16%|█▌        | 16/100 [00:14<01:22,  1.02steps/s, loss=0.436]     16%|█▌        | 16/100 [00:14<01:22,  1.02steps/s, loss=0.424]     17%|█▋        | 17/100 [00:15<01:18,  1.06steps/s, loss=0.424]     17%|█▋        | 17/100 [00:15<01:18,  1.06steps/s, loss=0.413]     18%|█▊        | 18/100 [00:16<01:16,  1.07steps/s, loss=0.413]     18%|█▊        | 18/100 [00:16<01:16,  1.07steps/s, loss=0.401]     19%|█▉        | 19/100 [00:17<01:14,  1.09steps/s, loss=0.401]     19%|█▉        | 19/100 [00:17<01:14,  1.09steps/s, loss=0.389]     20%|██        | 20/100 [00:18<01:12,  1.11steps/s, loss=0.389]     20%|██        | 20/100 [00:18<01:12,  1.11steps/s, loss=0.375]     21%|██        | 21/100 [00:18<01:10,  1.12steps/s, loss=0.375]     21%|██        | 21/100 [00:19<01:10,  1.12steps/s, loss=0.362]     22%|██▏       | 22/100 [00:19<01:09,  1.12steps/s, loss=0.362]     22%|██▏       | 22/100 [00:19<01:09,  1.12steps/s, loss=0.347]     23%|██▎       | 23/100 [00:20<01:07,  1.14steps/s, loss=0.347]     23%|██▎       | 23/100 [00:20<01:07,  1.14steps/s, loss=0.333]     24%|██▍       | 24/100 [00:21<01:05,  1.15steps/s, loss=0.333]     24%|██▍       | 24/100 [00:21<01:05,  1.15steps/s, loss=0.318]     25%|██▌       | 25/100 [00:22<01:04,  1.16steps/s, loss=0.318]     25%|██▌       | 25/100 [00:22<01:04,  1.16steps/s, loss=0.304]     26%|██▌       | 26/100 [00:23<01:09,  1.07steps/s, loss=0.304]     26%|██▌       | 26/100 [00:23<01:09,  1.07steps/s, loss=0.291]     27%|██▋       | 27/100 [00:24<01:06,  1.10steps/s, loss=0.291]     27%|██▋       | 27/100 [00:24<01:06,  1.10steps/s, loss=0.278]     28%|██▊       | 28/100 [00:25<01:04,  1.12steps/s, loss=0.278]     28%|██▊       | 28/100 [00:25<01:04,  1.12steps/s, loss=0.266]     29%|██▉       | 29/100 [00:25<01:02,  1.13steps/s, loss=0.266]     29%|██▉       | 29/100 [00:26<01:02,  1.13steps/s, loss=0.255]     30%|███       | 30/100 [00:26<01:01,  1.14steps/s, loss=0.255]     30%|███       | 30/100 [00:26<01:01,  1.14steps/s, loss=0.245]     31%|███       | 31/100 [00:27<01:00,  1.14steps/s, loss=0.245]     31%|███       | 31/100 [00:27<01:00,  1.14steps/s, loss=0.236]     32%|███▏      | 32/100 [00:28<00:59,  1.15steps/s, loss=0.236]     32%|███▏      | 32/100 [00:28<00:59,  1.15steps/s, loss=0.226]     33%|███▎      | 33/100 [00:29<00:58,  1.15steps/s, loss=0.226]     33%|███▎      | 33/100 [00:29<00:58,  1.15steps/s, loss=0.217]     34%|███▍      | 34/100 [00:30<00:57,  1.16steps/s, loss=0.217]     34%|███▍      | 34/100 [00:30<00:57,  1.16steps/s, loss=0.209]     35%|███▌      | 35/100 [00:31<00:56,  1.15steps/s, loss=0.209]     35%|███▌      | 35/100 [00:31<00:56,  1.15steps/s, loss=0.2]       36%|███▌      | 36/100 [00:32<01:00,  1.05steps/s, loss=0.2]     36%|███▌      | 36/100 [00:32<01:00,  1.05steps/s, loss=0.193]     37%|███▋      | 37/100 [00:33<00:58,  1.08steps/s, loss=0.193]     37%|███▋      | 37/100 [00:33<00:58,  1.08steps/s, loss=0.185]     38%|███▊      | 38/100 [00:34<00:56,  1.09steps/s, loss=0.185]     38%|███▊      | 38/100 [00:34<00:56,  1.09steps/s, loss=0.178]     39%|███▉      | 39/100 [00:34<00:55,  1.10steps/s, loss=0.178]     39%|███▉      | 39/100 [00:35<00:55,  1.10steps/s, loss=0.171]     40%|████      | 40/100 [00:35<00:54,  1.11steps/s, loss=0.171]     40%|████      | 40/100 [00:35<00:54,  1.11steps/s, loss=0.165]     41%|████      | 41/100 [00:36<00:52,  1.12steps/s, loss=0.165]     41%|████      | 41/100 [00:36<00:52,  1.12steps/s, loss=0.159]     42%|████▏     | 42/100 [00:37<00:51,  1.13steps/s, loss=0.159]     42%|████▏     | 42/100 [00:37<00:51,  1.13steps/s, loss=0.154]     43%|████▎     | 43/100 [00:38<00:50,  1.13steps/s, loss=0.154]     43%|████▎     | 43/100 [00:38<00:50,  1.13steps/s, loss=0.15]      44%|████▍     | 44/100 [00:39<00:49,  1.13steps/s, loss=0.15]     44%|████▍     | 44/100 [00:39<00:49,  1.13steps/s, loss=0.144]     45%|████▌     | 45/100 [00:40<00:48,  1.13steps/s, loss=0.144]     45%|████▌     | 45/100 [00:40<00:48,  1.13steps/s, loss=0.138]     46%|████▌     | 46/100 [00:41<00:52,  1.04steps/s, loss=0.138]     46%|████▌     | 46/100 [00:41<00:52,  1.04steps/s, loss=0.133]     47%|████▋     | 47/100 [00:42<00:49,  1.06steps/s, loss=0.133]     47%|████▋     | 47/100 [00:42<00:49,  1.06steps/s, loss=0.129]     48%|████▊     | 48/100 [00:43<00:48,  1.08steps/s, loss=0.129]     48%|████▊     | 48/100 [00:43<00:48,  1.08steps/s, loss=0.126]     49%|████▉     | 49/100 [00:44<00:46,  1.10steps/s, loss=0.126]     49%|████▉     | 49/100 [00:44<00:46,  1.10steps/s, loss=0.122]     50%|█████     | 50/100 [00:44<00:45,  1.11steps/s, loss=0.122]     50%|█████     | 50/100 [00:45<00:45,  1.11steps/s, loss=0.117]     51%|█████     | 51/100 [00:45<00:44,  1.11steps/s, loss=0.117]     51%|█████     | 51/100 [00:45<00:44,  1.11steps/s, loss=0.113]     52%|█████▏    | 52/100 [00:46<00:42,  1.12steps/s, loss=0.113]     52%|█████▏    | 52/100 [00:46<00:42,  1.12steps/s, loss=0.111]     53%|█████▎    | 53/100 [00:47<00:41,  1.13steps/s, loss=0.111]     53%|█████▎    | 53/100 [00:47<00:41,  1.13steps/s, loss=0.107]     54%|█████▍    | 54/100 [00:48<00:40,  1.14steps/s, loss=0.107]     54%|█████▍    | 54/100 [00:48<00:40,  1.14steps/s, loss=0.103]     55%|█████▌    | 55/100 [00:49<00:38,  1.16steps/s, loss=0.103]     55%|█████▌    | 55/100 [00:49<00:38,  1.16steps/s, loss=0.0999]     56%|█████▌    | 56/100 [00:50<00:37,  1.17steps/s, loss=0.0999]     56%|█████▌    | 56/100 [00:50<00:37,  1.17steps/s, loss=0.0969]     57%|█████▋    | 57/100 [00:51<00:40,  1.07steps/s, loss=0.0969]     57%|█████▋    | 57/100 [00:51<00:40,  1.07steps/s, loss=0.0957]     58%|█████▊    | 58/100 [00:52<00:38,  1.10steps/s, loss=0.0957]     58%|█████▊    | 58/100 [00:52<00:38,  1.10steps/s, loss=0.0947]     59%|█████▉    | 59/100 [00:52<00:36,  1.13steps/s, loss=0.0947]     59%|█████▉    | 59/100 [00:53<00:36,  1.13steps/s, loss=0.0929]     60%|██████    | 60/100 [00:53<00:35,  1.14steps/s, loss=0.0929]     60%|██████    | 60/100 [00:53<00:35,  1.14steps/s, loss=0.09]       61%|██████    | 61/100 [00:54<00:33,  1.15steps/s, loss=0.09]     61%|██████    | 61/100 [00:54<00:33,  1.15steps/s, loss=0.0856]     62%|██████▏   | 62/100 [00:55<00:32,  1.16steps/s, loss=0.0856]     62%|██████▏   | 62/100 [00:55<00:32,  1.16steps/s, loss=0.0824]     63%|██████▎   | 63/100 [00:56<00:31,  1.16steps/s, loss=0.0824]     63%|██████▎   | 63/100 [00:56<00:31,  1.16steps/s, loss=0.0807]     64%|██████▍   | 64/100 [00:57<00:30,  1.17steps/s, loss=0.0807]     64%|██████▍   | 64/100 [00:57<00:30,  1.17steps/s, loss=0.0792]     65%|██████▌   | 65/100 [00:58<00:29,  1.17steps/s, loss=0.0792]     65%|██████▌   | 65/100 [00:58<00:29,  1.17steps/s, loss=0.0788]     66%|██████▌   | 66/100 [00:58<00:29,  1.17steps/s, loss=0.0788]     66%|██████▌   | 66/100 [00:58<00:29,  1.17steps/s, loss=0.0772]     67%|██████▋   | 67/100 [00:59<00:30,  1.07steps/s, loss=0.0772]     67%|██████▋   | 67/100 [01:00<00:30,  1.07steps/s, loss=0.0759]     68%|██████▊   | 68/100 [01:00<00:28,  1.11steps/s, loss=0.0759]     68%|██████▊   | 68/100 [01:00<00:28,  1.11steps/s, loss=0.0736]     69%|██████▉   | 69/100 [01:01<00:27,  1.13steps/s, loss=0.0736]     69%|██████▉   | 69/100 [01:01<00:27,  1.13steps/s, loss=0.0714]     70%|███████   | 70/100 [01:02<00:26,  1.15steps/s, loss=0.0714]     70%|███████   | 70/100 [01:02<00:26,  1.15steps/s, loss=0.0691]     71%|███████   | 71/100 [01:03<00:24,  1.17steps/s, loss=0.0691]     71%|███████   | 71/100 [01:03<00:24,  1.17steps/s, loss=0.0677]     72%|███████▏  | 72/100 [01:04<00:23,  1.17steps/s, loss=0.0677]     72%|███████▏  | 72/100 [01:04<00:23,  1.17steps/s, loss=0.0657]     73%|███████▎  | 73/100 [01:04<00:22,  1.18steps/s, loss=0.0657]     73%|███████▎  | 73/100 [01:05<00:22,  1.18steps/s, loss=0.0655]     74%|███████▍  | 74/100 [01:05<00:21,  1.19steps/s, loss=0.0655]     74%|███████▍  | 74/100 [01:05<00:21,  1.19steps/s, loss=0.0654]     75%|███████▌  | 75/100 [01:06<00:20,  1.20steps/s, loss=0.0654]     75%|███████▌  | 75/100 [01:06<00:20,  1.20steps/s, loss=0.0655]     76%|███████▌  | 76/100 [01:07<00:19,  1.22steps/s, loss=0.0655]     76%|███████▌  | 76/100 [01:07<00:19,  1.22steps/s, loss=0.0656]     77%|███████▋  | 77/100 [01:08<00:20,  1.12steps/s, loss=0.0656]     77%|███████▋  | 77/100 [01:08<00:20,  1.12steps/s, loss=0.0623]     78%|███████▊  | 78/100 [01:09<00:19,  1.16steps/s, loss=0.0623]     78%|███████▊  | 78/100 [01:09<00:19,  1.16steps/s, loss=0.06]       79%|███████▉  | 79/100 [01:10<00:17,  1.17steps/s, loss=0.06]     79%|███████▉  | 79/100 [01:10<00:17,  1.17steps/s, loss=0.0587]     80%|████████  | 80/100 [01:10<00:16,  1.19steps/s, loss=0.0587]     80%|████████  | 80/100 [01:11<00:16,  1.19steps/s, loss=0.057]      81%|████████  | 81/100 [01:11<00:15,  1.20steps/s, loss=0.057]     81%|████████  | 81/100 [01:11<00:15,  1.20steps/s, loss=0.0562]     82%|████████▏ | 82/100 [01:12<00:14,  1.20steps/s, loss=0.0562]     82%|████████▏ | 82/100 [01:12<00:14,  1.20steps/s, loss=0.054]      83%|████████▎ | 83/100 [01:13<00:14,  1.21steps/s, loss=0.054]     83%|████████▎ | 83/100 [01:13<00:14,  1.21steps/s, loss=0.0535]     84%|████████▍ | 84/100 [01:14<00:13,  1.21steps/s, loss=0.0535]     84%|████████▍ | 84/100 [01:14<00:13,  1.21steps/s, loss=0.0549]     85%|████████▌ | 85/100 [01:15<00:12,  1.21steps/s, loss=0.0549]     85%|████████▌ | 85/100 [01:15<00:12,  1.21steps/s, loss=0.056]      86%|████████▌ | 86/100 [01:15<00:11,  1.21steps/s, loss=0.056]     86%|████████▌ | 86/100 [01:15<00:11,  1.21steps/s, loss=0.0587]     87%|████████▋ | 87/100 [01:16<00:10,  1.22steps/s, loss=0.0587]     87%|████████▋ | 87/100 [01:16<00:10,  1.22steps/s, loss=0.0547]     88%|████████▊ | 88/100 [01:17<00:10,  1.11steps/s, loss=0.0547]     88%|████████▊ | 88/100 [01:17<00:10,  1.11steps/s, loss=0.0513]     89%|████████▉ | 89/100 [01:18<00:09,  1.14steps/s, loss=0.0513]     89%|████████▉ | 89/100 [01:18<00:09,  1.14steps/s, loss=0.0507]     90%|█████████ | 90/100 [01:19<00:08,  1.17steps/s, loss=0.0507]     90%|█████████ | 90/100 [01:19<00:08,  1.17steps/s, loss=0.0506]     91%|█████████ | 91/100 [01:20<00:07,  1.16steps/s, loss=0.0506]     91%|█████████ | 91/100 [01:20<00:07,  1.16steps/s, loss=0.0494]     92%|█████████▏| 92/100 [01:21<00:06,  1.17steps/s, loss=0.0494]     92%|█████████▏| 92/100 [01:21<00:06,  1.17steps/s, loss=0.0469]     93%|█████████▎| 93/100 [01:21<00:05,  1.18steps/s, loss=0.0469]     93%|█████████▎| 93/100 [01:22<00:05,  1.18steps/s, loss=0.0448]     94%|█████████▍| 94/100 [01:22<00:05,  1.19steps/s, loss=0.0448]     94%|█████████▍| 94/100 [01:22<00:05,  1.19steps/s, loss=0.0453]     95%|█████████▌| 95/100 [01:23<00:04,  1.20steps/s, loss=0.0453]     95%|█████████▌| 95/100 [01:23<00:04,  1.20steps/s, loss=0.0459]     96%|█████████▌| 96/100 [01:24<00:03,  1.20steps/s, loss=0.0459]     96%|█████████▌| 96/100 [01:24<00:03,  1.20steps/s, loss=0.0462]     97%|█████████▋| 97/100 [01:25<00:02,  1.20steps/s, loss=0.0462]     97%|█████████▋| 97/100 [01:25<00:02,  1.20steps/s, loss=0.0497]     98%|█████████▊| 98/100 [01:26<00:01,  1.09steps/s, loss=0.0497]     98%|█████████▊| 98/100 [01:26<00:01,  1.09steps/s, loss=0.0526]     99%|█████████▉| 99/100 [01:27<00:00,  1.13steps/s, loss=0.0526]     99%|█████████▉| 99/100 [01:27<00:00,  1.13steps/s, loss=0.0502]    100%|██████████| 100/100 [01:28<00:00,  1.14steps/s, loss=0.0502]    100%|██████████| 100/100 [01:28<00:00,  1.14steps/s, loss=0.0502]




.. GENERATED FROM PYTHON SOURCE LINES 218-222

.. image-sg:: /generated/autoexamples/GPU/images/mrinufft_learn_unet.gif
   :alt: example learn_samples
   :srcset: /generated/autoexamples/GPU/images/mrinufft_learn_unet.gif
   :class: sphx-glr-single-img

.. GENERATED FROM PYTHON SOURCE LINES 224-225

Reconstruction from partially trained U-Net model

.. GENERATED FROM PYTHON SOURCE LINES 225-231

.. code-block:: Python

    model.eval()
    new_recon = model(kspace_mri_2D)
    fig, axs = plt.subplots(2, 2, figsize=(10, 10))
    plot_state(axs, mri_2D, init_traj, new_recon, losses)
    plt.show()




.. image-sg:: /generated/autoexamples/GPU/images/sphx_glr_example_fastMRI_UNet_002.png
   :alt: MR Image, Trajectory, Reconstruction, Loss
   :srcset: /generated/autoexamples/GPU/images/sphx_glr_example_fastMRI_UNet_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 232-240

References
==========

.. [fastmri] O. Ronneberger, P. Fischer, and Thomas Brox. U-net: Convolutional networks
          for biomedical image segmentation. In International Conference on Medical
          image computing and computer-assisted intervention, pages 234–241.
          Springer, 2015.
          https://github.com/facebookresearch/fastMRI/blob/main/fastmri/models/unet.py


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (1 minutes 33.833 seconds)


.. _sphx_glr_download_generated_autoexamples_GPU_example_fastMRI_UNet.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/mind-inria/mri-nufft/gh-pages?urlpath=lab/tree/examples/generated/autoexamples/GPU/example_fastMRI_UNet.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: example_fastMRI_UNet.ipynb <example_fastMRI_UNet.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: example_fastMRI_UNet.py <example_fastMRI_UNet.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: example_fastMRI_UNet.zip <example_fastMRI_UNet.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
