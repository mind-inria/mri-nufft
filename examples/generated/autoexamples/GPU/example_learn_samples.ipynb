{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class='alert alert-warning'>\n\n# Need GPU warning\n\nRunning this mri-nufft example requires a GPU, and hence is NOT possible on binder currently We request you to kindly run this notebook on Google Colab by clicking the link below. Additionally, please make sure to set the runtime on Colab to use a GPU and install the below libraries before running.\n</div>\n<div class=\"colab-button\">\n            <a href=\"https://colab.research.google.com/github/mind-inria/mri-nufft/blob/gh-pages/examples/generated/autoexamples/GPU/example_learn_samples.ipynb\" target=\"_blank\">\n                <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" \n                alt=\"Open In Colab\"/>\n            </a>\n        </div>\n        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Learn Sampling pattern\n\nA small pytorch example to showcase learning k-space sampling patterns.\nThis example showcases the auto-diff capabilities of the NUFFT operator\nwrt to k-space trajectory in mri-nufft.\n\nIn this example, we solve the following optimization problem:\n\n\\begin{align}\\mathbf{\\hat{K}} =  \\mathrm{arg} \\min_{\\mathbf{K}} ||  \\mathcal{F}_\\mathbf{K}^* D_\\mathbf{K} \\mathcal{F}_\\mathbf{K} \\mathbf{x} - \\mathbf{x} ||_2^2\\end{align}\n\nwhere $\\mathcal{F}_\\mathbf{K}$ is the forward NUFFT operator and $D_\\mathbf{K}$ is the density compensators for trajectory $\\mathbf{K}$,  $\\mathbf{x}$ is the MR image which is also the target image to be reconstructed.\n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>This example only showcases the autodiff capabilities, the learned sampling pattern is not scanner compliant as the scanner gradients required to implement it violate the hardware constraints. In practice, a projection $\\Pi_\\mathcal{Q}(\\mathbf{K})$ into the scanner constraints set $\\mathcal{Q}$ is recommended (see [Proj]_). This is implemented in the proprietary SPARKLING package [Sparks]_. Users are encouraged to contact the authors if they want to use it.</p></div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Install libraries\n!pip install mri-nufft[gpunufft] scikit-image\n!pip install brainweb-dl  # Required for data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport time\nimport joblib\n\nimport brainweb_dl as bwdl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom tqdm import tqdm\nfrom PIL import Image, ImageSequence\n\nfrom mrinufft import get_operator\nfrom mrinufft.trajectories import initialize_2D_radial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup a simple class to learn trajectory\n<div class=\"alert alert-info\"><h4>Note</h4><p>While we are only learning the NUFFT operator, we still need the gradient ``wrt_data=True`` to be setup in ``get_operator`` to have all the gradients computed correctly.\n    See [Projector]_ for more details.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BACKEND = os.environ.get(\"MRINUFFT_BACKEND\", \"gpunufft\")\n\n\nclass Model(torch.nn.Module):\n    def __init__(self, inital_trajectory):\n        super(Model, self).__init__()\n        self.trajectory = torch.nn.Parameter(\n            data=torch.Tensor(inital_trajectory),\n            requires_grad=True,\n        )\n        self.operator = get_operator(BACKEND, wrt_data=True, wrt_traj=True)(\n            self.trajectory.detach().cpu().numpy(),\n            shape=(256, 256),\n            density=True,\n            squeeze_dims=False,\n        )\n\n    def forward(self, x):\n        # Update the trajectory in the NUFFT operator.\n        # Note that the re-computation of density compensation happens internally.\n        self.operator.samples = self.trajectory.clone()\n\n        # A simple acquisition model simulated with a forward NUFFT operator\n        kspace = self.operator.op(x)\n\n        # A simple density compensated adjoint operator\n        adjoint = self.operator.adj_op(kspace)\n        return adjoint / torch.linalg.norm(adjoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Util function to plot the state of the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_state(axs, mri_2D, traj, recon, loss=None, save_name=None):\n    axs = axs.flatten()\n    axs[0].imshow(np.abs(mri_2D[0]), cmap=\"gray\")\n    axs[0].axis(\"off\")\n    axs[0].set_title(\"MR Image\")\n    axs[1].scatter(*traj.T, s=1)\n    axs[1].set_title(\"Trajectory\")\n    axs[2].imshow(np.abs(recon[0][0].detach().cpu().numpy()), cmap=\"gray\")\n    axs[2].axis(\"off\")\n    axs[2].set_title(\"Reconstruction\")\n    if loss is not None:\n        axs[3].plot(loss)\n        axs[3].set_title(\"Loss\")\n        axs[3].grid(\"on\")\n    if save_name is not None:\n        plt.savefig(save_name, bbox_inches=\"tight\")\n        plt.close()\n    else:\n        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup model and optimizer\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "init_traj = initialize_2D_radial(16, 512).reshape(-1, 2).astype(np.float32)\nmodel = Model(init_traj)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nschedulder = torch.optim.lr_scheduler.LinearLR(\n    optimizer, start_factor=1, end_factor=0.1, total_iters=100\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mri_2D = torch.Tensor(np.flipud(bwdl.get_mri(4, \"T1\")[80, ...]).astype(np.complex64))[\n    None\n]\nmri_2D = mri_2D / torch.linalg.norm(mri_2D)\nmodel.eval()\nrecon = model(mri_2D)\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\nplot_state(axs, mri_2D, init_traj, recon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Start training loop\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "losses = []\nimage_files = []\nmodel.train()\nwith tqdm(range(100), unit=\"steps\") as tqdms:\n    for i in tqdms:\n        out = model(mri_2D)\n        loss = torch.norm(out - mri_2D[None])\n        numpy_loss = loss.detach().cpu().numpy()\n        tqdms.set_postfix({\"loss\": numpy_loss})\n        losses.append(numpy_loss)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        with torch.no_grad():\n            # Clamp the value of trajectory between [-0.5, 0.5]\n            for param in model.parameters():\n                param.clamp_(-0.5, 0.5)\n        schedulder.step()\n        # Generate images for gif\n        hashed = joblib.hash((i, \"learn_traj\", time.time()))\n        filename = \"/tmp/\" + f\"{hashed}.png\"\n        fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n        plot_state(\n            axs,\n            mri_2D,\n            model.trajectory.detach().cpu().numpy(),\n            out,\n            losses,\n            save_name=filename,\n        )\n        image_files.append(filename)\n\n\n# Make a GIF of all images.\nimgs = [Image.open(img) for img in image_files]\nimgs[0].save(\n    \"mrinufft_learn_traj.gif\",\n    save_all=True,\n    append_images=imgs[1:],\n    optimize=False,\n    duration=2,\n    loop=0,\n)\n\n# sphinx_gallery_thumbnail_path = 'generated/autoexamples/GPU/images/mrinufft_learn_traj.gif'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. image-sg:: /generated/autoexamples/GPU/images/mrinufft_learn_traj.gif\n   :alt: example learn_samples\n   :srcset: /generated/autoexamples/GPU/images/mrinufft_learn_traj.gif\n   :class: sphx-glr-single-img\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trained trajectory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.eval()\nrecon = model(mri_2D)\nfig, axs = plt.subplots(2, 2, figsize=(10, 10))\nplot_state(axs, mri_2D, model.trajectory.detach().cpu().numpy(), recon, losses)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### References\n\n.. [Proj] N. Chauffert, P. Weiss, J. Kahn and P. Ciuciu, \"A Projection Algorithm for\n          Gradient Waveforms Design in Magnetic Resonance Imaging,\" in\n          IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2026-2039, Sept. 2016,\n          doi: 10.1109/TMI.2016.2544251.\n.. [Sparks] Chaithya GR, P. Weiss, G. Daval-Fr√©rot, A. Massire, A. Vignaud and P. Ciuciu,\n          \"Optimizing Full 3D SPARKLING Trajectories for High-Resolution Magnetic\n          Resonance Imaging,\" in IEEE Transactions on Medical Imaging, vol. 41, no. 8,\n          pp. 2105-2117, Aug. 2022, doi: 10.1109/TMI.2022.3157269.\n.. [Projector] Chaithya GR, and Philippe Ciuciu. 2023. \"Jointly Learning Non-Cartesian\n          k-Space Trajectories and Reconstruction Networks for 2D and 3D MR Imaging\n          through Projection\" Bioengineering 10, no. 2: 158.\n          https://doi.org/10.3390/bioengineering10020158\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}