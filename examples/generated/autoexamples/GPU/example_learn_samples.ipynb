{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "!pip install mri-nufft[cufinufft,finufft,gpunufft,extra,autodiff]\n!pip install brainweb-dl fastmri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Learn Sampling pattern\n\nA small pytorch example to showcase learning k-space sampling patterns.\nThis example showcases the auto-diff capabilities of the NUFFT operator\nwrt to k-space trajectory in mri-nufft.\n\nIn this example, we solve the following optimization problem:\n\n\\begin{align}\\mathbf{\\hat{K}} =  \\mathrm{arg} \\min_{\\mathbf{K}} ||  \\mathcal{F}_\\mathbf{K}^* D_\\mathbf{K} \\mathcal{F}_\\mathbf{K} \\mathbf{x} - \\mathbf{x} ||_2^2\\end{align}\n\nwhere $\\mathcal{F}_\\mathbf{K}$ is the forward NUFFT operator and $D_\\mathbf{K}$ is the density compensators for trajectory $\\mathbf{K}$,  $\\mathbf{x}$ is the MR image which is also the target image to be reconstructed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nimport brainweb_dl as bwdl\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport numpy as np\nimport torch\n\nfrom mrinufft import get_operator\nfrom mrinufft.trajectories import initialize_2D_radial\nfrom mrinufft.trajectories.projection import project_trajectory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup a simple class to learn trajectory\n<div class=\"alert alert-info\"><h4>Note</h4><p>While we are only learning the NUFFT operator, we still need the gradient ``wrt_data=True`` to be setup in ``get_operator`` to have all the gradients computed correctly.\n    See [Projector]_ for more details.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "BACKEND = os.environ.get(\"MRINUFFT_BACKEND\", \"gpunufft\")\n\nplt.rcParams[\"animation.embed_limit\"] = 2**30  # 1GiB is very large.\n\n\nclass Model(torch.nn.Module):\n    def __init__(self, inital_trajectory):\n        super(Model, self).__init__()\n        self.trajectory = torch.nn.Parameter(\n            data=torch.Tensor(inital_trajectory),\n            requires_grad=True,\n        )\n        self.operator = get_operator(BACKEND, wrt_data=True, wrt_traj=True)(\n            self.trajectory.detach().cpu().numpy(),\n            shape=(256, 256),\n            density=True,\n            squeeze_dims=False,\n        )\n\n    def forward(self, x):\n        # Update the trajectory in the NUFFT operator.\n        # Note that the re-computation of density compensation happens internally.\n        self.operator.samples = self.trajectory.clone().reshape(-1, 2)\n\n        # A simple acquisition model simulated with a forward NUFFT operator\n        kspace = self.operator.op(x)\n\n        # A simple density compensated adjoint operator\n        adjoint = self.operator.adj_op(kspace)\n        return adjoint / torch.linalg.norm(adjoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Data and Model\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_epochs = 50\n\nmri_2D = torch.Tensor(np.flipud(bwdl.get_mri(4, \"T1\")[80, ...]).astype(np.complex64))\nmri_2D = mri_2D[None, ...] / torch.linalg.norm(mri_2D)\n\ninit_traj = initialize_2D_radial(32, 512).astype(np.float32)\ninit_traj += 0.01 * np.random.randn(*init_traj.shape).astype(\n    np.float32\n)  # Add some noise to the initial trajectory\ninit_traj = project_trajectory(\n    init_traj, max_iter=100, verbose=0, TE_pos=0\n)  # Project the initial trajectory to satisfy hardware constraints\nmodel = Model(init_traj)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\nschedulder = torch.optim.lr_scheduler.LinearLR(\n    optimizer, start_factor=1, end_factor=1e-4, total_iters=num_epochs\n)\n\n\nmodel.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and plotting\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "recon = model(mri_2D)\n\nfig, axs = plt.subplots(2, 2, figsize=(10, 10))\nfig.suptitle(\"Training Starting\")\naxs = axs.flatten()\n\naxs[0].imshow(np.abs(mri_2D[0]), cmap=\"gray\")\naxs[0].axis(\"off\")\naxs[0].set_title(\"MR Image\")\n\ntraj_plot = []\nfor traj in init_traj:\n    traj_plot.append(axs[1].plot(*traj.T, c=\"b\"))\naxs[1].set_title(\"Trajectory\")\n\nrecon_im = axs[2].imshow(np.abs(recon.squeeze().detach().cpu().numpy()), cmap=\"gray\")\naxs[2].axis(\"off\")\naxs[2].set_title(\"Reconstruction\")\n(loss_curve,) = axs[3].plot([], [])\naxs[3].grid()\naxs[3].set_xlabel(\"epochs\")\naxs[3].set_ylabel(\"loss\")\n\nfig.tight_layout()\n\n\ndef train():\n    \"\"\"Train loop.\"\"\"\n    losses = []\n    for i in range(num_epochs):\n        out = model(mri_2D)\n        loss = torch.norm(out - mri_2D[None])  # Compute loss\n\n        optimizer.zero_grad()  # Zero gradients\n        loss.backward()  # Backward pass\n        optimizer.step()  # Update weights\n        with torch.no_grad():\n            # clamp the value of trajectory between [-0.5, 0.5]\n            for param in model.parameters():\n                param = project_trajectory(param, max_iter=100, verbose=0)\n                model.trajectory.data = param.clamp_(-0.5, 0.5)\n        schedulder.step()\n        losses.append(loss.item())\n        yield (\n            out.detach().cpu().numpy().squeeze(),\n            model.trajectory.detach().cpu().numpy(),\n            losses,\n        )\n\n\ndef plot_epoch(data):\n    img, traj, losses = data\n\n    cur_epoch = len(losses)\n    recon_im.set_data(abs(img))\n    loss_curve.set_xdata(np.arange(cur_epoch))\n    loss_curve.set_ydata(losses)\n    for plot, t in zip(traj_plot, traj):\n        plot[0].set_data(*t.T)\n\n    axs[3].set_xlim(0, cur_epoch)\n    axs[3].set_ylim(0, 1.1 * max(losses))\n    axs[2].set_title(f\"Reconstruction, frame {cur_epoch}/{num_epochs}\")\n    axs[1].set_title(f\"Trajectory, frame {cur_epoch}/{num_epochs}\")\n\n    if cur_epoch < num_epochs:\n        fig.suptitle(\"Training in progress \" + \".\" * (1 + cur_epoch % 3))\n    else:\n        fig.suptitle(\"Training complete !\")\n\n\nani = animation.FuncAnimation(\n    fig, plot_epoch, train, save_count=num_epochs, repeat=False\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### References\n\n.. [Proj] N. Chauffert, P. Weiss, J. Kahn and P. Ciuciu, \"A Projection Algorithm for\n          Gradient Waveforms Design in Magnetic Resonance Imaging,\" in\n          IEEE Transactions on Medical Imaging, vol. 35, no. 9, pp. 2026-2039, Sept. 2016,\n          doi: 10.1109/TMI.2016.2544251.\n.. [Sparks] Chaithya GR, P. Weiss, G. Daval-Fr\u00e9rot, A. Massire, A. Vignaud and P. Ciuciu,\n          \"Optimizing Full 3D SPARKLING Trajectories for High-Resolution Magnetic\n          Resonance Imaging,\" in IEEE Transactions on Medical Imaging, vol. 41, no. 8,\n          pp. 2105-2117, Aug. 2022, doi: 10.1109/TMI.2022.3157269.\n.. [Projector] Chaithya GR, and Philippe Ciuciu. 2023. \"Jointly Learning Non-Cartesian\n          k-Space Trajectories and Reconstruction Networks for 2D and 3D MR Imaging\n          through Projection\" Bioengineering 10, no. 2: 158.\n          https://doi.org/10.3390/bioengineering10020158\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}