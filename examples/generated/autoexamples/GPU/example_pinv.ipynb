{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "!pip install mri-nufft[cufinufft,finufft,gpunufft,extra,autodiff]\n!pip install brainweb-dl fastmri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Least Squares Image Reconstruction\n\nAn example to show how to reconstruct volumes using the least square estimate.\n\nThis script demonstrates the use of the Conjugate Gradient (CG), LSQR and LSMR\nmethods, to reconstruct images from non-uniform k-space data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport time\nfrom tqdm.auto import tqdm\nimport cupy as cp\nimport numpy as np\nfrom brainweb_dl import get_mri\nfrom matplotlib import pyplot as plt\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\n\nimport mrinufft\nfrom mrinufft.extras.optim import loss_l2_reg, loss_l2_AHreg\n\nBACKEND = os.environ.get(\"MRINUFFT_BACKEND\", \"cufinufft\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup Inputs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "samples_loc = mrinufft.initialize_2D_spiral(Nc=64, Ns=512, nb_revolutions=8)\nground_truth = get_mri(sub_id=4)\nground_truth = ground_truth[90]\n# Normalize the ground truth image\nground_truth = ground_truth / np.sqrt(np.mean(abs(ground_truth) ** 2))\nimage_gpu = cp.array(ground_truth)  # convert to cupy array for GPU processing\n\nprint(\"image size: \", ground_truth.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup the NUFFT operator\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "NufftOperator = mrinufft.get_operator(BACKEND)  # get the operator\n\nnufft = NufftOperator(\n    samples_loc,\n    shape=ground_truth.shape,\n    squeeze_dims=True,\n)  # create the NUFFT operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reconstruct the image using the CG method\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kspace_data_gpu = nufft.op(image_gpu)  # get the k-space data\nkspace_data = kspace_data_gpu.get()  # convert back to numpy array for display\nadjoint = nufft.adj_op(kspace_data_gpu).get()  # adjoint NUFFT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pseudo-inverse solver\nThe least-square solution to the inverse problem can be obtained by solving\nthe following optimization problem:\n\n\\begin{align}\\min_x \\|Ax - b\\|_2^2\\end{align}\n\nwhere $A$ is the NUFFT operator, $x$ is the image to be\nreconstructed, and $b$ is the k-space data. The optimization problem can\nbe solved using different iterative solvers, such as Conjugate Gradient (CG),\nLSQR and LSMR. The solvers are implemented in the :meth:`mrinufft.pinv_solver`\nmethod, which takes as input the k-space data, the maximum number of\niterations, and the optimization method to use.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Callback monitoring\nWe can monitor the convergence of the optimization by using a callback function\nthat is called at each iteration of the optimization. The callback function can\ncompute different metrics, such as the residual norm, the PSNR, or the time taken\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def mixed_cb(*args, **kwargs):\n    \"\"\"A compound callback function, to track iterations time and convergence.\"\"\"\n    return [\n        time.perf_counter(),\n        loss_l2_reg(*args, **kwargs),\n        loss_l2_AHreg(*args, **kwargs),\n        psnr(\n            abs(args[0].get().squeeze()),\n            abs(ground_truth.squeeze()),\n            data_range=ground_truth.max(),\n        ),\n        time.perf_counter(),\n    ]\n\n\ndef process_cb_results(cb_results):\n    t0, r, rH, psnrs, t1 = list(zip(*cb_results))\n    t1 = (t0[0], *t1[:-1])\n    time_it = np.cumsum(np.array(t0) - np.array(t1))\n    r = [rr.get() for rr in r]\n    rH = [rr.get() for rr in rH]\n\n    return {\"time\": time_it, \"res\": r, \"AHres\": rH, \"psnr\": psnrs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run the least-square minimization for all the solvers\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "OPTIM = [\"cg\", \"lsqr\", \"lsmr\"]\nMETRICS = {\n    \"res\": r\"$\\|Ax-b\\|$\",\n    \"AHres\": r\"$\\|A^H(Ax-b)\\|$\",\n    \"psnr\": \"PSNR\",\n}\n\nMAX_ITER = 1000\n\nimages = dict()\niterations_cb = dict()\npg = tqdm(total=MAX_ITER, position=0, leave=True)\nfor optim in OPTIM:\n    image, iter_cb = nufft.pinv_solver(\n        kspace_data=kspace_data_gpu,\n        max_iter=MAX_ITER,\n        callback=mixed_cb,\n        optim=optim,\n        progressbar=pg,\n    )\n    images[optim] = image.get().squeeze()  # retrieve image from GPU.\n    iterations_cb[optim] = process_cb_results(iter_cb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display Convergence\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(len(METRICS), 1, sharex=True, figsize=(8, 12))\nfor i, metric in enumerate(METRICS):\n    for optim in OPTIM:\n        if \"res\" in metric:\n            axs[i].set_yscale(\"log\")\n        axs[i].plot(\n            iterations_cb[optim][\"time\"],\n            iterations_cb[optim][metric],\n            marker=\"o\",\n            markevery=20,\n            label=f\"{optim} {np.mean(1/np.diff(iterations_cb[optim]['time'])):.2f}iters/s\",\n        )\n    axs[i].grid()\n    axs[i].set_ylabel(METRICS[metric])\naxs[0].legend()\naxs[-1].set_xlabel(\"time (s)\")\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display images\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, len(OPTIM) + 2, figsize=(20, 7))\n\nfor i, optim in enumerate(OPTIM):\n    axs[i].imshow(abs(images[optim]), cmap=\"gray\", origin=\"lower\")\n    axs[i].axis(\"off\")\n    axs[i].set_title(\n        f\"{optim} reconstruction\\n PSNR: {iterations_cb[optim]['psnr'][-1]:.2f}dB \\n\"\n        f\"{len(iterations_cb[optim]['time'])} iters ({iterations_cb[optim]['time'][-1]:.2f}s)\"\n    )\n\naxs[-1].imshow(abs(ground_truth), cmap=\"gray\", origin=\"lower\")\naxs[-1].axis(\"off\")\naxs[-1].set_title(\"Original image\")\naxs[-2].imshow(\n    abs(adjoint),\n    cmap=\"gray\",\n    origin=\"lower\",\n)\naxs[-2].axis(\"off\")\naxs[-2].set_title(\n    f\"Adjoint NUFFT \\n PSNR: {psnr(abs(adjoint), abs(ground_truth), data_range=ground_truth.max()):.2f}dB\"\n)\n\nfig.suptitle(\"Reconstructed images using different optimizers\")\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using a damping regularization term\n\nThe least-square problem can be regularized using a damping term to improve the\nconditioning of the problem.\nThis is done by solving the following optimization problem:\n\n\\begin{align}\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#    \\min_x \\|Ax - b\\|_2^2 + \\gamma \\|x\\|_2^2\n\n# where :math:`\\gamma` is the regularization parameter.\n\n\nimages = dict()\niterations_cb = dict()\n\npg = tqdm(total=MAX_ITER, position=0, leave=True)\nfor optim in OPTIM:\n    image, iter_cb = nufft.pinv_solver(\n        kspace_data=kspace_data_gpu,\n        max_iter=1000,\n        callback=mixed_cb,\n        damp=0.1,\n        optim=optim,\n        progressbar=pg,\n    )\n    images[optim] = image.get().squeeze()  # retrieve image from GPU.\n    iterations_cb[optim] = process_cb_results(iter_cb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display Convergence\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(len(METRICS), 1, sharex=True, figsize=(8, 12))\nfor i, metric in enumerate(METRICS):\n    for optim in OPTIM:\n        if \"res\" in metric:\n            axs[i].set_yscale(\"log\")\n        axs[i].plot(\n            iterations_cb[optim][\"time\"],\n            iterations_cb[optim][metric],\n            marker=\"o\",\n            markevery=20,\n            label=f\"{optim} {np.mean(1/np.diff(iterations_cb[optim]['time'])):.2f}iters/s\",\n        )\n    axs[i].grid()\n    axs[i].set_ylabel(METRICS[metric])\naxs[0].legend()\naxs[-1].set_xlabel(\"time (s)\")\nfig.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display images\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, len(OPTIM) + 2, figsize=(20, 7))\n\nfor i, optim in enumerate(OPTIM):\n    axs[i].imshow(abs(images[optim]), cmap=\"gray\", origin=\"lower\")\n    axs[i].axis(\"off\")\n    axs[i].set_title(\n        f\"{optim} reconstruction\\n PSNR: {iterations_cb[optim]['psnr'][-1]:.2f}dB \\n\"\n        f\"{len(iterations_cb[optim]['time'])} iters ({iterations_cb[optim]['time'][-1]:.2f}s)\"\n    )\n\naxs[-1].imshow(abs(ground_truth), cmap=\"gray\", origin=\"lower\")\naxs[-1].axis(\"off\")\naxs[-1].set_title(\"Original image\")\naxs[-2].imshow(\n    abs(adjoint),\n    cmap=\"gray\",\n    origin=\"lower\",\n)\naxs[-2].axis(\"off\")\naxs[-2].set_title(\n    f\"Adjoint NUFFT \\n PSNR: {psnr(abs(adjoint), abs(ground_truth), data_range=ground_truth.max()):.2f}dB\"\n)\n\nfig.suptitle(\"Reconstructed images using different optimizers\")\nfig.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}